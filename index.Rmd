# Practical Machine Learning Project
##  Abstract

This is the Writeup of the Pratical Machine Learning Peer Assessment.
We do some preprocessing on the pml-training file, build tree based models, use cross validation, compute out of sample error and predict test cases on the pml-testing set.. 

## Preprocessing

We load the files pml-training.csv and pml-testing.csv into R and do some cleaning. Inspecting the training file, we find that there are 19622 observations of 160 variables. In one hundred of these variables 90 percent or more observations
are not available (NA). We drop these variables and result in a data set training with 19622 observations of 60 variables.

We split this training set with the createDataPartition() function from the caret package
into two parts. One, again called training, containing 80 percent of the data,
actually used for modelling, the 
rest, called validation, for cross validation of the models.

The first seven variables of the training set contain observations not relevant for modelling and are dropped. We finally have a training set with 11776 obeservations of 53 variables.

## Tree Based Model with Package rpart

We load the rpart library and construct a decison tree on the training set
with the rpart() function.

```{r eval = FALSE }
library(rpart)
### make decision tree
fitTree = rpart(class ~ ., data = training, method = "class")
### predict on training
predictTrain = predict(fitTree, newdata = training, type = "class")
### predict on validation
predictValid = predict(fitTree, newdata = validation, type = "class")
```
We compute the in sample error manually; the result is 0.2519.

``` {r eval = FALSE }
inerr = 1 - sum(predictTrain == training$class)/ length(training$class)
```

We compute the out sample error manually; the result is 0.2543.

``` {r eval = FALSE }
outerr = 1 - sum(predictValid == validation$class)/ length(validation$class)
```

